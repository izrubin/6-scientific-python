{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "-------------\n",
    "\n",
    "**1) Complete this notebook and make a pull request:** \n",
    "\n",
    "Answer questions (Q) in the space provided (A) in this notebook. When finished, copy your notebook to the `Assignment/` directory and name it `nb-6.5-<Github-username>.ipynb`. Then make a pull request to the upstream repo. The entered answers in this notebook will be simply Markdown text where I want you to interpret and describe a block of code to better understand what it is doing. Much of this code you will have seen already. \n",
    "\n",
    "\n",
    "**2) Write an importable Python package, save as a repo, and test it here.**\n",
    "\n",
    "The package should be written as we did in our last lession (`.py` files in a directory with a setup.py file so it can be installed with `pip`). Follow instructions at the end of this notebook for how to write your package. Test it here by importing the package and executing the code at the end. It should work and give correct answers, if not, continue working on it. When you have it completed save your package as a new Github repo named `seqlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `seqlib` package\n",
    "\n",
    "Together we are going to write several functions here that will make up your new package called `seqlib`. It will be your job to copy these functions, organize them into a Class, save the code into a `.py` file (you can use SublimeText if you're comfortable with it for much of this, or any text editor including the one in jupyter), package the files so they can be imported as a library, and test the package so that it accomplishes the tasks which are defined at the end of this notebook. First things first, though, let's write the functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q.  Describe what the `mutate()` function below does:\n",
    "\n",
    "\n",
    "A. The `mutate()` function starts by creating a variable `diff` which is equal to \"ACTG\" minus the base that you call for the function. Then it returns a random choosing of one of the three remaining bases left over from the `diff` variable. So if you run `mutate(\"T\")` it will never output a 'T', as this is not in the result of `diff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(base):\n",
    "    diff = set(\"ACTG\") - set(base)\n",
    "    return np.random.choice(list(diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it\n",
    "mutate(\"T\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q. Describe how the `simulate()` function below works:\n",
    "Annotate the code by inserting lines with comments as you read through the function to make sense of it. What is being created at each step and how is it used?\n",
    "\n",
    "\n",
    "A. I think this function generates an array of variable sequence data. It returns a matrix of what you call, number of ninds by nsites. It sets the original sequence equal to a random choice of bases. The arr is sat as an array for original sequence of the range of ninds. Then it introduces mutations. IT iterates through colummns of range of nsites, and for any missing sequence data, sets it to print an 'N'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(ninds, nsites):       # requires 2 arguments\n",
    "    oseq = np.random.choice(list(\"ACGT\"), size=nsites) # sets oseq equal to a random choice, size of nsites, in ACGT\n",
    "    arr = np.array([oseq for i in range(ninds)])   # create sequence of nsites\n",
    "    muts = np.random.binomial(1, 0.1, (ninds, nsites)) # introduce mutations, random binomial distribution\n",
    "    for col in range(nsites):  # for column in range of nsites\n",
    "        newbase = mutate(arr[0, col])  #set newbase = to mutate function applied to the arr for all columns\n",
    "        mask = muts[:, col].astype(bool) # mask = random binomial for all collummns, set as type boolean\n",
    "        arr[:, col][mask] = newbase # sets newbase as both arguments\n",
    "    missing = np.random.binomial(1, 0.1, (ninds, nsites)) # determines if it is missing\n",
    "    arr[missing.astype(bool)] = \"N\"  #if it is missing, return an N\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['C', 'T', 'A', 'A', 'N', 'G', 'G', 'C', 'A', 'N', 'C', 'G', 'G',\n",
       "        'T', 'C'],\n",
       "       ['C', 'T', 'A', 'A', 'A', 'G', 'G', 'C', 'A', 'A', 'C', 'G', 'T',\n",
       "        'C', 'C'],\n",
       "       ['C', 'T', 'A', 'A', 'N', 'C', 'G', 'G', 'A', 'A', 'C', 'C', 'T',\n",
       "        'C', 'G'],\n",
       "       ['T', 'T', 'A', 'A', 'T', 'C', 'G', 'G', 'A', 'A', 'N', 'G', 'T',\n",
       "        'C', 'C'],\n",
       "       ['T', 'T', 'A', 'N', 'N', 'N', 'N', 'C', 'A', 'A', 'C', 'G', 'G',\n",
       "        'C', 'C'],\n",
       "       ['C', 'T', 'A', 'N', 'A', 'C', 'T', 'C', 'A', 'T', 'A', 'G', 'G',\n",
       "        'C', 'C']], dtype='<U1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate(6,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['G' 'G' 'C' 'A' 'G' 'C' 'A' 'T' 'C' 'G' 'G' 'N' 'G' 'T' 'T']\n",
      " ['N' 'G' 'A' 'A' 'G' 'N' 'A' 'T' 'C' 'G' 'G' 'T' 'G' 'T' 'T']\n",
      " ['G' 'G' 'C' 'A' 'G' 'C' 'A' 'T' 'A' 'A' 'G' 'T' 'G' 'T' 'T']\n",
      " ['G' 'G' 'C' 'A' 'N' 'C' 'A' 'N' 'C' 'G' 'G' 'T' 'G' 'N' 'T']\n",
      " ['G' 'G' 'C' 'A' 'G' 'C' 'N' 'T' 'C' 'G' 'G' 'T' 'G' 'T' 'T']\n",
      " ['G' 'G' 'N' 'T' 'G' 'C' 'A' 'A' 'C' 'G' 'G' 'G' 'G' 'T' 'T']]\n"
     ]
    }
   ],
   "source": [
    "seqs = simulate(6, 15)  #matrix size 6 by 15\n",
    "print(seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q: Describe how the `filter_missing` function works:**\n",
    "Annotate the code by inserting lines with comments as you read through the function to make sense of it. How does it find columns with missing (N) values in them? How might you mprove it?\n",
    "\n",
    "A. Filtering for missing alleles. Find frequency of missing alleles by summing the instances of \"N\" and dividing it by the shape of the array. Then it returns the array with columns that have a frequency of missing bases which is less than the specified maximum frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_missing(arr, maxfreq):   #sequence of nsitres, a=max frequency\n",
    "    freqmissing = np.sum(arr == \"N\", axis=0) / arr.shape[0]  #missing if the sum of\n",
    "    return arr[:, freqmissing <= maxfreq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['G', 'A', 'C', 'G', 'G', 'G', 'T'],\n",
       "       ['G', 'A', 'C', 'G', 'G', 'G', 'T'],\n",
       "       ['G', 'A', 'A', 'A', 'G', 'G', 'T'],\n",
       "       ['G', 'A', 'C', 'G', 'G', 'G', 'T'],\n",
       "       ['G', 'A', 'C', 'G', 'G', 'G', 'T'],\n",
       "       ['G', 'T', 'C', 'G', 'G', 'G', 'T']], dtype='<U1')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_missing(seqs, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q: Describe how the `filter_maf` function works:**\n",
    "Annotate the code by inserting lines with comments as you read through the function to make sense of it. How does it calculate minor allele frequencies? Why does it use copy?\n",
    "\n",
    "A. Filtering for minor allele frequency. It takes frequencies bigger than .5 and replaces it with 1 - frequency. Which is a copy of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_maf(arr, minfreq):  # filter for minor allele frequency\n",
    "    freqs = np.sum(arr != arr[0], axis=0) / arr.shape[0] # frequency determined if the sum does not equal zero\n",
    "    maf = freqs.copy() # copies\n",
    "    maf[maf > 0.5] = 1 - maf[maf > 0.5]  #\n",
    "    return arr[:, maf > minfreq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['G', 'C', 'A', 'G', 'C', 'A', 'T', 'C', 'G', 'N', 'T'],\n",
       "       ['N', 'A', 'A', 'G', 'N', 'A', 'T', 'C', 'G', 'T', 'T'],\n",
       "       ['G', 'C', 'A', 'G', 'C', 'A', 'T', 'A', 'A', 'T', 'T'],\n",
       "       ['G', 'C', 'A', 'N', 'C', 'A', 'N', 'C', 'G', 'T', 'N'],\n",
       "       ['G', 'C', 'A', 'G', 'C', 'N', 'T', 'C', 'G', 'T', 'T'],\n",
       "       ['G', 'N', 'T', 'G', 'C', 'A', 'A', 'C', 'G', 'G', 'T']],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_maf(seqs, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What order should these functions be applied, does it matter?\n",
    "\n",
    "A. I don't think it matters what order the functions are applied, since they returned the same array. But I think it makes sense the second way, to filter maf once you've removed the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['A', 'C', 'G'],\n",
       "       ['A', 'C', 'G'],\n",
       "       ['A', 'A', 'A'],\n",
       "       ['A', 'C', 'G'],\n",
       "       ['A', 'C', 'G'],\n",
       "       ['T', 'C', 'G']], dtype='<U1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_missing(filter_maf(seqs, 0.1), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['A', 'C', 'G'],\n",
       "       ['A', 'C', 'G'],\n",
       "       ['A', 'A', 'A'],\n",
       "       ['A', 'C', 'G'],\n",
       "       ['A', 'C', 'G'],\n",
       "       ['T', 'C', 'G']], dtype='<U1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_maf(filter_missing(seqs, 0.1), 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Describe how `calculate_statistics()` works\n",
    "\n",
    "\n",
    "A. Calculates each desired factor, and then has it printed by calling the name and returning the variable it was made equal to in defining the function. Prints as a pandas series, text then the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculcate_statistics(arr):\n",
    "    nd = np.var(arr == arr[0], axis=0).mean() #calculating the mean of the array\n",
    "    mf = np.mean(np.sum(arr != arr[0], axis=0) / arr.shape[0]) #freq calculated by dividing sum of maf by whole sum\n",
    "    inv = np.any(arr != arr[0], axis=0).sum() # sums invariant sites\n",
    "    var = arr.shape[1] - inv #subtracts invariant from total\n",
    "    return pd.Series(\n",
    "        {\"mean nucleotide diversity\": nd,\n",
    "         \"mean minor allele frequency\": mf,\n",
    "         \"invariant sites\": inv,\n",
    "         \"variable sites\": var,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "invariant sites                12.000000\n",
       "mean minor allele frequency     0.255556\n",
       "mean nucleotide diversity       0.150000\n",
       "variable sites                  3.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculcate_statistics(seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions: Write a `seqlib` Class object\n",
    "\n",
    "I started writing the bare bones of it below. You should write it so that it can be executed as described below to perform all of the functions we defined above, and so that its attributes can be accessed. Save this class object in a `.py` file and make it into an importable package called `seqlib`. You can write and test your object in this notebook if you like, but it must be saved separately in a `.py` file and be imported. You cannot execute the code at the end using your object defined here in the notebook. When finished save your package to GitHub as a repo just like we did with the `helloworld` package. You do not need to write a CLI script like we did for the `helloworld` package, we will only be using the Python API here. See the examples below for **how you should write your Class object**. It should be able to run in the way written below, so look at that code and think about how you would write a Class object that can do that. \n",
    "\n",
    "While you can mostly copy the functions from above, you will need to modify them slightly to access information about the Class object using *self*. For example, the `simulate()` function below takes self as a first argument and can access `self.inds` and `self.nsites` from that, so we do not need to provide those as arguments to the `simulate` function like we did above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class seqlib:\n",
    "    def __init__(self, ninds, nsites):\n",
    "        self.ninds = ninds\n",
    "        self.nsites = nsites\n",
    "        self.seqs = self.simulate()\n",
    "    \n",
    "    def mutate(self, base):\n",
    "        diff = set(\"ACTG\") - set(base)\n",
    "        return np.random.choice(list(diff))\n",
    "        \n",
    "    def simulate(self):\n",
    "        ninds = self.ninds\n",
    "        nsites = self.nsites\n",
    "        oseq = np.random.choice(list(\"ACGT\"), size=nsites) \n",
    "        arr = np.array([oseq for i in range(ninds)])   \n",
    "        muts = np.random.binomial(1, 0.1, (ninds, nsites)) \n",
    "        for col in range(nsites):  \n",
    "            newbase = mutate(arr[0, col]) \n",
    "            mask = muts[:, col].astype(bool) \n",
    "            arr[:, col][mask] = newbase \n",
    "        missing = np.random.binomial(1, 0.1, (ninds, nsites)) \n",
    "        arr[missing.astype(bool)] = \"N\"  \n",
    "        return arr\n",
    "    \n",
    "    def filter_missing(self, maxfreq):   \n",
    "        arr = self.seqs\n",
    "        freqmissing = np.sum(arr == \"N\", axis=0) / arr.shape[0]  \n",
    "        return arr[:, freqmissing <= maxfreq]\n",
    "    \n",
    "    def filter(self, minfreq, maxfreq):  \n",
    "        maf = self.filter_maf(self.filter_missing(maxfreq), minfreq)\n",
    "        return maf\n",
    "    \n",
    "    def filter_maf(self, minmaf):\n",
    "        freqs = np.sum(arr != arr[0], axis=0) / arr.shape[0]\n",
    "        maf = freqs.copy()\n",
    "        maf[maf > 0.5] = 1 - maf[maf > 0.5]\n",
    "        return arr[:, maf > minmaf]\n",
    "    \n",
    "    def maf(self):\n",
    "        freqs = np.sum(arr != arr[0], axis=0) / arr.shape[0]\n",
    "        maf = freqs.copy()\n",
    "        maf[maf > 0.5] = 1 - maf[maf > 0.5]\n",
    "        return freqs\n",
    "    \n",
    "    \n",
    "    def calculcate_statistics(self):\n",
    "        nd = np.var(arr == arr[0], axis=0).mean() #calculating the mean of the array\n",
    "        mf = np.mean(np.sum(arr != arr[0], axis=0) / arr.shape[0]) #freq calculated by dividing sum of maf by whole sum\n",
    "        inv = np.any(arr != arr[0], axis=0).sum() \n",
    "        var = arr.shape[1] - inv \n",
    "        return pd.Series(\n",
    "            {\"mean nucleotide diversity\": nd,\n",
    "             \"mean minor allele frequency\": mf,\n",
    "             \"invariant sites\": inv,\n",
    "             \"variable sites\": var,\n",
    "            })      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your package\n",
    "The package should be globally importable (you ran `pip install .` or `pip install -e .` to install it), and it should be able to execute the following code without error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chloehacker/PDSB/seqlib\n",
      "/Users/chloehacker/PDSB/seqlib/seqlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "setup = \"\"\"\n",
    "from setuptools import setup\n",
    "setup(\n",
    "    name=\"mypackage\",\n",
    "    version=\"0.1\",\n",
    "    packages=[\"seqlib\"],\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "init = \"\"\"\n",
    "from .seqlib import seqlib\n",
    "\"\"\"\n",
    "\n",
    "seqlib = \"\"\"\n",
    "def seqlib():\n",
    "    print(\"hello world\")\n",
    "\"\"\"\n",
    "\n",
    "## let's define some names that we'll use for paths\n",
    "prjname = \"seqlib\"\n",
    "pkgname = \"seqlib\"\n",
    "storeloc = os.path.expanduser(\"~/PDSB/\")\n",
    "\n",
    "## now let's create some joint paths with the os module\n",
    "prjpath = os.path.join(storeloc, prjname)\n",
    "pkgpath = os.path.join(storeloc, prjname, pkgname)\n",
    "\n",
    "## check out paths\n",
    "print(prjpath)\n",
    "print(pkgpath)\n",
    "\n",
    "## make the directories (exist_ok allows for it to already exist)\n",
    "os.makedirs(pkgpath, exist_ok=True)\n",
    "\n",
    "\n",
    "## write setup.py file\n",
    "with open(os.path.join(prjpath, \"setup.py\"), 'w') as out:\n",
    "    out.write(setup)\n",
    "    \n",
    "## write init file\n",
    "with open(os.path.join(pkgpath, \"__init__.py\"), 'w') as out:\n",
    "    out.write(init)\n",
    "    \n",
    "## write script to file\n",
    "with open(os.path.join(pkgpath, \"seqlib.py\"), 'w') as out:\n",
    "    out.write(seqlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seqlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-47fa57607e3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseqlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seqlib'"
     ]
    }
   ],
   "source": [
    "import seqlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
